---
title: "ECON 104 Project 1"
author: "Marc Luzuriaga, Takuya Sugahara, Daniel Day, Shabib Alam"
date: "2023-10-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = TRUE, message = TRUE)
#Installing the POE5data set for the first time

install.packages("devtools")
devtools::install_github("ccolonescu/POE5Rdata")
library (POE5Rdata)

#install.packages("AER")
library(AER)

#Other Libraries
#install.packages("xtable")
library(xtable) # makes data frame for kable, which is a package to print tables

#install.packages("jtools")
library(jtools) #for short display of the regressions 
# # This allows to use summ(Reg) instead of summary(reg)
# set_summ_defaults(digits = 3) #decimal ditits of numerical outputs

#install.packages("fitdistrplus")
library(fitdistrplus)

#install.packages("stats4")
library(stats4)

#install.packages("MASS")
library(MASS)

# for other necessary test or graphical tools
#install.packages("survival")
library(survival)

#install.packages("actuar")
library(actuar)

#install.packages("distrMod")
library(distrMod)

#install.packages("effects") # Useful package to plot marginal effects
library(effects)
```

```{r}
#Loading in the MurderRates Data Set
data("MurderRates")
```

`{set(echo = TRUE)}`

# [**1 Introduction: Murder Rate Determinants**]{.underline}

## 1.1 Data Set Summary

In this paper, we will be analyzing the Murder Rate Data Set from the AER Package. The data set holds cross-sectional data on states in the year 1950, and the data set contains 44 observations on the following 8 variables:

(1) rate: Murder rate per 100,000 (FBI estimate, 1950)

(2) convictions: Number of convictions divided by number of murders in 1950.

(3) executions: Average number of executions during 1946-1950 divided by convictions in 1950.

(4) time: Median time served (in months) of convicted murderers released in 1951.

(5) income: Median family income in 1949 (in 1,000 USD).

(6) lfp: Labor force participation rate in 1950 (in percent).

(7) noncauc: Proportion of population that is non-Caucasian in 1950.

(8) Southern: Factor indicating region

## 1.2 Question

The question we seek to answer with the Murder Rates Data Set is as follows: "Does the Median family income in 1949 (in 1,000 USD) or the median time served (in months) of convicted murderers released in 1951 have a greater effect in reducing murder rates in states?" For the purposes of this project, our group will claim that the median family income in 1949 (in 1,000 USD) will have a greater effect on decreasing murder rates than an increased median time served in prison.

## 1.3 Descriptive Analysis of Variables

### 1.3.1 Graphs

The graph below illustrates a histogram displaying the frequencies with respect to the Murder Rate per 100,000. The histogram portrays the fact that most states have a murder rate of 0-4 per 100,000, with a mode of approximately between three and four.

Notice that the histogram is right-skewed with a long tail towards the right. This resembles a specification error of a log normal distribution. We will correct for this specification error by taking the log of the log normal distribution to give us the normal distribution in the following sections.

```{r}
#Histogram
hist(MurderRates$rate, col='grey',main = "Histogram of Murder Rate",xlab = "Murder rate per 100,000")
```

Delving deeper into the statistics, the graphs below shows the empirical density and cumulative distribution for the dependent variable. In particular, the fitted distributions support the previous fact that the dependent variable's central tendency is approximately centered around four because the cumulative distribution's 50th percentile is roughly around four.

Also, the fitted distributions also suggest that there is a specification error with the model because of the data being right-skewed.

```{r}
#Fitted Distributions
plotdist(MurderRates$rate, histo = TRUE, demp = TRUE)
```

In order to create precise estimates about the statistics of the data set, we have included a five number summary below. The mean of the rate, convictions, executions, time, income, and lfp variables are 5.404, 0.2605, 0.06034, 136.5, 1.7681, and 53.07, respectively. Also, the median of the rate, convictions, executions, time, income, and lfp variables are 3.625, 0.2260, 0.045, 124, 1.83, 53.40, respectively.

```{r}
rates_summary <- MurderRates[, c(1,2,3,4,5,6)]
summary(rates_summary)
```

Next, we present a Box Plot for the dependent variable. An interesting insight that the box plot provides us is that the data set contains a single outlier of 19.25 murders per 100,000.

```{r}
#Box Plot For MurderRates
boxplot(MurderRates$rate, main="MurderRates")
```

Finally, we present the correlation matrix. The correlation between the murder rate and executions in 0.1727, a positive relationship. The correlation between the murder rate and convictions is -0.25113. The correlation between the murder rate and executions is 0.172793. The correlation between the murder rate and time is -0.51858. The correlation between the murder rate and income is -0.65428.

```{r}
#Correlation Matrix
my_data <- MurderRates[, c(1,2,3,4,5.6)]
cor(my_data)
```

### 1.3.2 Possible Violations of Regression Assumptions

The most possible but apparent violation of the regression assumptions would be homoskedasticity. According to the linear regression assumption of homoskedasticity, linear regressions must have a constant variance in its error term. However, by analyzing the variables, we observe multiple clues towards heteroskedasticity.

First, the histogram reveals that the data set has an incorrect transformation of the dependent variable. The histogram is right-skewed with a long tail towards the right. This resembles a specification error of a log normal distribution and may indicate the presence of heteroskedasticity. We will need to correct for this specification error by taking the log of the log normal distribution to give us the normal distribution.

Second, the box plot reveals that there is an outlier in the dependent variable. Although the 3rd quartile of the rates variable is 7.725 per 100,000, the data set contains a data point of 19.25 murders per 100,000. An outlier may cause heteroskedasticity.

Third, the mixing of observation of different scales in the income variable may cause heteroskedasticity. The income variable ranges from 0.760 to 2.390 (in 1,000 USD). The mixing of high-income households with low-income households may cause heteroskedasticity.

------------------------------------------------------------------------

# [2 The Model]{.underline}

## 2.1 The Multiple Linear Regression Model

### 2.1.1 Model and Inference

[**Shabib: Step 3**]{.underline}

```{r}
library(AER)  # Load the AER package
data("MurderRates")
```

#### xIn this following model:

"rate" is the response variable (Murder Rates), which is the variable I want to predict. "convictions," "executions," "times," "lfp," and "income" are the predictor variables I want to include in the model. These variables will be used to explain or predict the variation in Murder rates.

```{r}
str(MurderRates)
Reg <- lm(rate~income+time+executions+convictions+lfp+noncauc+southern, data = MurderRates)
summary(Reg)
```

### Commenting on the overall fit of the model:

#### R-Squared :

The model has an R-squared which is 0.6327. This is a reasonably good R-squared value. Adjusted R-squared is 0.5844 providing slightly more conservative of model fit.

#### F-statistic:

F-statistic is 13.09 and a very low p-value is 1.953e-07 which indicates that the model is statistically significant since p-value is very lower than F-statistics.

#### Coefficient significance:

Coefficients provide information about their statical significance. From the model, income and time have highly significant coefficients with very low p-values. For that reason, if income or time changes, others predictor will have effect.

We will estimate the relationship between the rate, execution, time, income, convictions with the following Multiple Regression Model:

$$\\ {MURDERRATES} = 7.65042 + (-7.03778) INCOME+ (-0.02635)  TIME + 9.63458  EXECUTION+ (-4.73854) CONVICTIONS+ 0.27394  LFP +\epsilon_{i}$$

Our claim about the income variable having a greater effect in decreasing rates than time can be precisely modeled by the following inference:

$$ H_{0}: (-7.03778) - (-0.02635) \ge 0 \\H_{1}: (-7.03778) - (-0.02635) < 0$$

```{r}
#Partial effect of Income on Rates
install.packages("effects")
library(effects)
effincome <- effect("income", Reg)
plot(effincome)
```

```{r}
#Partial effect of Executions on Rates
efftime <- effect("time", Reg)
plot(efftime)
```

```{r}
#Partial effect of Executions on Rates
effexecutions <- effect("executions", Reg)
plot(effexecutions)
```

```{r}
#Partial effect of Executions on Rates
effconvictions <- effect("convictions", Reg)
plot(effconvictions)
```

```{r}
#Partial effect of Executions on Rates
effnoncauc <- effect("noncauc", Reg)
plot(effnoncauc)
```

```{r}
#Partial effect of Executions on Rates
effsouthern <- effect("southern", Reg)
plot(effsouthern)
```

### 2.1.2 Testing Multicollinearity

[**Shabib: Step 4**]{.underline} ####Multicollinearity using VIF:

```{r}
library(car)
vif_values <- vif(reg)  # Assuming 'Reg' is your original regression model
summary(vif_values)
```

Based on the VIF analysis, I don't need to remove any varaibles from my model since VIF values are within range. \##### Here is why: Min: The minimum VIF is 1.096 which means low multicollinearity.

1st Qu.: 1st 25 percentile of all VIF values is 1.109 which is close to 1. That's mean this is also under low multicollinearity.

Median: 1.157 is the median of all variables which means median is also under multicollinearity.

Mean: Mean with 1.345 indecates relatively low of multicollineairity.

3rd Qu.: The VIF value at the 75th percentile of your predictor variables is approximately 1.660, which is still relatively close to 1. This indicates that the majority of your predictor variables have low multicollinearity.

Max: The maximum value among all the predictors is 1.700 which is not present highly multicollinearity. This indicates that all predictor's VIF is under 1.7 which is low multicollinearity.

Because of this result, we don't need to remove any variables.

Min. 1st Qu. Median Mean 3rd Qu. Max. 1.096 1.109 1.157 1.345 1.660 1.700

## 2.2 The New Model

### 2.2.1 Akaike Information Criterion

[**Taku: Step 5**]{.underline}

. . . . .

### 2.2.2 Plotting Residuals Versus Fitted Values

[**Taku: Step 6**]{.underline}

. . . . .

### 2.2.3 RESET Test

[**Marc: Step 7**]{.underline}

. . . . .

------------------------------------------------------------------------

# [3 Heteroskedasticity]{.underline}

## 3.1 Testing For Heteroskedasticity

[**Danny: Step 8**]{.underline}

. . . . .

## 3.2 Correcting For Heteroskedasticity

[**Danny: Step 9**]{.underline}

. . . . .

------------------------------------------------------------------------

# [4 Conclusion]{.underline}
